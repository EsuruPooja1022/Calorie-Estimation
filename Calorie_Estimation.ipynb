{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d964beed-1fa3-4cb1-9c6c-5cb078545ebe",
      "metadata": {
        "id": "d964beed-1fa3-4cb1-9c6c-5cb078545ebe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166664b7-7dad-4e50-ad15-905e853619f6",
      "metadata": {
        "id": "166664b7-7dad-4e50-ad15-905e853619f6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"C:\\\\Users\\\\Bala\\\\Downloads\\\\IndianFoodDatasetCSV.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfc9144-f28a-4aae-b384-1f1534ada31d",
      "metadata": {
        "id": "3dfc9144-f28a-4aae-b384-1f1534ada31d"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7260723e-a2a8-475c-bace-51023673a38b",
      "metadata": {
        "id": "7260723e-a2a8-475c-bace-51023673a38b"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a4be20-4266-433f-9bd3-1ef75f3c83ed",
      "metadata": {
        "id": "a4a4be20-4266-433f-9bd3-1ef75f3c83ed"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "df['Cuisine'].value_counts().plot(kind='bar')\n",
        "plt.title('Distribution of Cuisine')\n",
        "plt.xlabel('Cuisine')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95cb76c4-14ba-469f-a65a-11884f91d076",
      "metadata": {
        "id": "95cb76c4-14ba-469f-a65a-11884f91d076"
      },
      "outputs": [],
      "source": [
        "calorie_map = {\n",
        "    'idli': 39,\n",
        "    'dosa': 133,\n",
        "    'pongal': 200,\n",
        "    'sambar': 150,\n",
        "    'biryani (veg)': 250,\n",
        "    'biryani (chicken)': 300,\n",
        "    'vada': 156,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72f2b76-24a9-454d-acf2-5d1d883103d7",
      "metadata": {
        "id": "e72f2b76-24a9-454d-acf2-5d1d883103d7"
      },
      "outputs": [],
      "source": [
        "predicted_class = 'dosa'  # Example: Predicted class from the model\n",
        "calorie_value = calorie_map.get(predicted_class, \"Unknown\")\n",
        "print(f\"Predicted Food Item: {predicted_class}\")\n",
        "print(f\"Calorie Value: {calorie_value} kcal\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967d5df4-3646-4d47-a4cd-0c83c04ef3d8",
      "metadata": {
        "id": "967d5df4-3646-4d47-a4cd-0c83c04ef3d8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Set paths\n",
        "dataset_path = \"C:\\\\Users\\\\Bala\\\\Downloads\\\\images\"  # Update this path\n",
        "image_size = (224, 224)  # Resize images to 224x224 (for CNN compatibility)\n",
        "\n",
        "# Initialize variables\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Debug: List files in the dataset path\n",
        "print(f\"Files in the dataset path: {os.listdir(dataset_path)}\")\n",
        "\n",
        "# Load images and labels\n",
        "for file_name in os.listdir(dataset_path):\n",
        "    if file_name.endswith('.jpg'):  # Consider only images\n",
        "        try:\n",
        "            # Read and preprocess the image\n",
        "            img = cv2.imread(os.path.join(dataset_path, file_name))\n",
        "            if img is not None:  # Check if image is valid\n",
        "                img = cv2.resize(img, image_size)\n",
        "                images.append(img)\n",
        "\n",
        "                # Extract label from filename (example: \"Chapati.jpg\" -> \"Chapati\")\n",
        "                label = file_name.split('.')[0]\n",
        "                labels.append(label)\n",
        "            else:\n",
        "                print(f\"Failed to load image: {file_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {file_name}: {e}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "images = np.array(images) / 255.0  # Normalize pixel values\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Debug: Check the number of loaded images and labels\n",
        "print(f\"Loaded {len(images)} images and {len(labels)} labels.\")\n",
        "\n",
        "# Encode labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split dataset\n",
        "if len(images) > 0:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(\"Dataset Loaded and Preprocessed\")\n",
        "    print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
        "else:\n",
        "    print(\"No images were loaded. Please check the dataset path or image files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2cf6e3-923e-4a91-9ae3-3d21b1d02057",
      "metadata": {
        "id": "ab2cf6e3-923e-4a91-9ae3-3d21b1d02057"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the uploaded ZIP file and extraction path\n",
        "zip_file_path = \"C:\\\\Users\\\\Bala\\\\Downloads\\\\images.zip\"\n",
        "extraction_path = \"C:\\\\Users\\\\Bala\\\\Downloads\\\\southfoodimages\"\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Define the image folder (update this path if necessary)\n",
        "image_folder = os.path.join(extraction_path, 'Indian-Food-Classification-main/uploads')\n",
        "\n",
        "# List image files in the folder\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]\n",
        "print(f\"Found {len(image_files)} images.\")\n",
        "\n",
        "# Display the first 5 images\n",
        "for i, image_file in enumerate(image_files[:5]):\n",
        "    # Load the image using cv2\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
        "\n",
        "    # Plot the image\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(image)\n",
        "    plt.title(image_file)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79c0e0dd-fdf2-4f99-aab5-60a27bcd7685",
      "metadata": {
        "id": "79c0e0dd-fdf2-4f99-aab5-60a27bcd7685"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Inspect the extraction directory\n",
        "for root, dirs, files in os.walk(extraction_path):\n",
        "    print(f\"Directory: {root}\")\n",
        "    print(f\"Subdirectories: {dirs}\")\n",
        "    print(f\"Files: {files}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c699770-abda-4ca2-84b1-d153d6bd9a03",
      "metadata": {
        "id": "9c699770-abda-4ca2-84b1-d153d6bd9a03"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paths to the uploaded ZIP file and extraction directory\n",
        "zip_file_path = r\"C:\\Users\\Bala\\Downloads\\images.zip\"  # Use raw string to handle backslashes\n",
        "extraction_path = r\"C:\\Users\\Bala\\Downloads\\southfood\"  # Ensure this directory exists\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Define the image folder\n",
        "image_folder = extraction_path  # Images should now be directly in the extracted path\n",
        "\n",
        "# List image files in the folder\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Print the number of images found\n",
        "print(f\"Found {len(image_files)} images.\")\n",
        "\n",
        "# Display the first 5 images\n",
        "for i, image_file in enumerate(image_files[:5]):\n",
        "    # Construct the full image path\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "    # Load the image using cv2\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
        "\n",
        "        # Plot the image\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.imshow(image)\n",
        "        plt.title(image_file)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Failed to load image: {image_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f5c558-d4a5-47ed-a3e3-b4bd4198fcc5",
      "metadata": {
        "id": "a0f5c558-d4a5-47ed-a3e3-b4bd4198fcc5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "extraction_path = r\"C:\\Users\\Bala\\Downloads\\southfood\"\n",
        "\n",
        "# Walk through the extracted directory and list all files\n",
        "for root, dirs, files in os.walk(extraction_path):\n",
        "    print(f\"Directory: {root}\")\n",
        "    print(f\"Files: {files}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f02e486d-918d-4bb4-9ddf-ab6d08fd739a",
      "metadata": {
        "id": "f02e486d-918d-4bb4-9ddf-ab6d08fd739a"
      },
      "outputs": [],
      "source": [
        "image_folder = r\"C:\\Users\\Bala\\Downloads\\southfood\\images\"  # Update this path based on the debug output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ee1487-4f20-47b4-ae1e-f33b2fde727b",
      "metadata": {
        "id": "29ee1487-4f20-47b4-ae1e-f33b2fde727b"
      },
      "outputs": [],
      "source": [
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f14799fc-2bfc-4861-bc3a-6799577fd0e5",
      "metadata": {
        "id": "f14799fc-2bfc-4861-bc3a-6799577fd0e5"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the ZIP file and extraction folder\n",
        "zip_file_path = r\"C:\\Users\\Bala\\Downloads\\images.zip\"\n",
        "extraction_path = r\"C:\\Users\\Bala\\Downloads\\southfood\"\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Define the folder containing the images\n",
        "image_folder = extraction_path  # Update this path if images are in a subfolder\n",
        "\n",
        "# List image files in the folder\n",
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "# Check if images are found\n",
        "if len(image_files) == 0:\n",
        "    print(\"No images found in the folder.\")\n",
        "else:\n",
        "    print(f\"Found {len(image_files)} images.\")\n",
        "\n",
        "# Number of rows and columns for the grid\n",
        "rows, cols = 2, 3  # Adjust as needed\n",
        "\n",
        "# Plot images in a grid\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(12, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i < len(image_files):\n",
        "        # Load the image\n",
        "        image_path = os.path.join(image_folder, image_files[i])\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(os.path.splitext(image_files[i])[0])  # Use filename as the title\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        # Hide unused subplots\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81b2181-a672-4fd0-8e08-57a7eb82ecd7",
      "metadata": {
        "id": "b81b2181-a672-4fd0-8e08-57a7eb82ecd7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the folder containing the images\n",
        "image_folder = r\"C:\\Users\\Bala\\Desktop\\Indian Food Images\"  # Updated file path\n",
        "\n",
        "# List image files in the folder\n",
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "# Check if images are found\n",
        "if len(image_files) == 0:\n",
        "    print(\"No images found in the folder.\")\n",
        "else:\n",
        "    print(f\"Found {len(image_files)} images.\")\n",
        "\n",
        "# Number of rows and columns for the grid\n",
        "rows, cols = 2, 3  # Adjust as needed\n",
        "\n",
        "# Plot images in a grid\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(12, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i < len(image_files):\n",
        "        # Load the image\n",
        "        image_path = os.path.join(image_folder, image_files[i])\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(os.path.splitext(image_files[i])[0])  # Use filename as the title\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        # Hide unused subplots\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c96d8d52-d173-4f5e-b3eb-50b396e72d4b",
      "metadata": {
        "id": "c96d8d52-d173-4f5e-b3eb-50b396e72d4b"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define paths for the dataset\n",
        "zip_file_path = \"C:\\\\Users\\\\Bala\\\\Downloads\\\\images.zip\"  # Replace with the actual path\n",
        "extracted_path = 'images_extracted/'\n",
        "\n",
        "# Extract the zip file\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "# Get all image file names in the extracted folder\n",
        "image_files = [f for f in os.listdir(extracted_path) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "# Resize and display the first 10 images\n",
        "resized_images = []\n",
        "for img_file in image_files[:10]:  # Process first 10 images\n",
        "    img_path = os.path.join(extracted_path, img_file)\n",
        "    with Image.open(img_path) as img:\n",
        "        resized_img = img.resize((128, 128))  # Resize to 128x128\n",
        "        resized_images.append(resized_img)\n",
        "\n",
        "# Show resized images\n",
        "for resized_img in resized_images:\n",
        "    resized_img.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dc7e34-d279-45dc-b586-aa45be9fb96b",
      "metadata": {
        "id": "a3dc7e34-d279-45dc-b586-aa45be9fb96b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Assuming 'resized_images' contains the resized images (ensure they are created first)\n",
        "\n",
        "# Create a grid to display the first 10 resized images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2 rows, 5 columns\n",
        "\n",
        "# Display each image in the grid\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(resized_images):\n",
        "        ax.imshow(resized_images[i])\n",
        "        ax.axis('off')  # Hide axes\n",
        "    else:\n",
        "        ax.axis('off')  # Hide unused grid cells\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716f5cf7-081c-45b3-a400-fc07ff6aec0e",
      "metadata": {
        "id": "716f5cf7-081c-45b3-a400-fc07ff6aec0e"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "vm=cv2.imread(r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\")\n",
        "plt.imshow(vm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd37289-7db8-49fa-a2a9-f5efbc5a7972",
      "metadata": {
        "id": "ebd37289-7db8-49fa-a2a9-f5efbc5a7972"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "vm=cv2.imread(r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\")\n",
        "plt.imshow(vm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e7ff0bb-538c-4131-9a51-a0528b8bd4fe",
      "metadata": {
        "id": "1e7ff0bb-538c-4131-9a51-a0528b8bd4fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25577aa7-22cf-4736-93a4-a900133dc868",
      "metadata": {
        "id": "25577aa7-22cf-4736-93a4-a900133dc868"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\"\n",
        "]\n",
        "\n",
        "# Create a figure for the images\n",
        "fig, axes = plt.subplots(1, len(image_paths), figsize=(15, 5))\n",
        "\n",
        "# Loop through the images and display them\n",
        "for i, path in enumerate(image_paths):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image in the corresponding subplot\n",
        "    axes[i].imshow(img_rgb)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(f\"Image {i+1}\")  # Optional title\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eed05c6-f980-4b65-8594-57b9c26d7296",
      "metadata": {
        "id": "6eed05c6-f980-4b65-8594-57b9c26d7296"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Create a figure for the images\n",
        "fig, axes = plt.subplots(1, len(image_paths), figsize=(15, 5))\n",
        "\n",
        "# Loop through the images and display them\n",
        "for i, path in enumerate(image_paths):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image in the corresponding subplot\n",
        "    axes[i].imshow(img_rgb)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(f\"Image {i+1}\")  # Optional title\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f167b96-cd80-46e8-beda-447354ebe3e8",
      "metadata": {
        "id": "7f167b96-cd80-46e8-beda-447354ebe3e8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Create a 2x3 grid for the images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "\n",
        "# Loop through the images and display them\n",
        "for i, path in enumerate(image_paths):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i // 4, i % 4].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image in the corresponding subplot\n",
        "    ax = axes[i // 3, i % 3]\n",
        "    ax.imshow(img_rgb)\n",
        "    ax.axis('off')  # Hide axes\n",
        "    ax.set_title(f\"Image {i+1}\")  # Optional title\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(len(image_paths), 6):  # Adjust 6 for the total grid slots (2x3)\n",
        "    axes[j // 4, j % 4].axis('off')\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26ac015-02a7-4871-8f24-b85e6b13da19",
      "metadata": {
        "id": "c26ac015-02a7-4871-8f24-b85e6b13da19"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load pre-trained model (ResNet50) and freeze its layers\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build your model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='linear')  # Output layer for calorie prediction\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d951994-00fe-417b-9ccf-06711342b0ed",
      "metadata": {
        "id": "9d951994-00fe-417b-9ccf-06711342b0ed"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_calories(image_path, model):\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    predicted_calories = model.predict(img_array)\n",
        "    return predicted_calories[0][0]\n",
        "\n",
        "# Predict\n",
        "calories = predict_calories(r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\", model)\n",
        "print(f\"Predicted Calories: {calories}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d44b13-a51b-4a55-aeb5-5aecbff17f19",
      "metadata": {
        "id": "f6d44b13-a51b-4a55-aeb5-5aecbff17f19"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_calories(image_path, model):\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    predicted_calories = model.predict(img_array)\n",
        "    return predicted_calories[0][0]\n",
        "\n",
        "# Predict\n",
        "calories = predict_calories( r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\", model)\n",
        "print(f\"Predicted Calories: {calories}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cc663b-8984-4717-84e3-49eee70eae64",
      "metadata": {
        "id": "c5cc663b-8984-4717-84e3-49eee70eae64"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Path to the image folder\n",
        "image_folder = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\"\n",
        "\n",
        "# Example calorie data (create your own or generate it dynamically)\n",
        "calorie_data = {\n",
        "    \"filename\": [\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\51ho3ce412c.webp\"],\n",
        "    \"calories\": [250]  # Replace these with real calorie estimates\n",
        "}\n",
        "\n",
        "# Convert the data to a DataFrame\n",
        "calorie_df = pd.DataFrame(calorie_data)\n",
        "\n",
        "# Resize dimensions for the images\n",
        "img_size = (224, 224)\n",
        "\n",
        "# Prepare image data and labels\n",
        "images = []\n",
        "calories = []\n",
        "\n",
        "for _, row in calorie_df.iterrows():\n",
        "    img_path = os.path.join(image_folder, row['filename'])\n",
        "    if os.path.exists(img_path):\n",
        "        # Load the image\n",
        "        img = load_img(img_path, target_size=img_size)\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
        "        images.append(img_array)\n",
        "        calories.append(row['calories'])\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "images = np.array(images)\n",
        "calories = np.array(calories)\n",
        "\n",
        "print(f\"Image shape: {images.shape}, Calorie shape: {calories.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "266e731f-5ec3-43ce-993f-494f35800dab",
      "metadata": {
        "id": "266e731f-5ec3-43ce-993f-494f35800dab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# South Indian food dataset\n",
        "data = {\n",
        "    'Food Item': ['Dosa', 'Idli', 'Sambar', 'Vada', 'Pongal', 'Biryani', 'Uttapam',\n",
        "                  'Rava Kesari', 'Masala Dosa', 'Appam', 'Chettinad Curry', 'Pesarattu',\n",
        "                  'Puliyodarai', 'Curd Rice'],\n",
        "    'Category': ['Breakfast', 'Breakfast', 'Soup', 'Snack', 'Breakfast', 'Main Course',\n",
        "                 'Breakfast', 'Dessert', 'Snack', 'Breakfast', 'Main Course', 'Breakfast',\n",
        "                 'Main Course', 'Side Dish'],\n",
        "    'Calories': [120, 39, 150, 180, 350, 250, 150, 200, 350, 150, 450, 250, 300, 150],\n",
        "    'Serving Size (g)': [150, 100, 200, 100, 200, 300, 150, 100, 200, 120, 250, 150, 200, 200]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Bar Plot for Calories by Food Item\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='Food Item', y='Calories', data=df, palette='viridis')\n",
        "plt.title('Calories per South Indian Food Item')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# 2. Pie Chart for Food Category Distribution\n",
        "category_counts = df['Category'].value_counts()\n",
        "plt.figure(figsize=(8,8))\n",
        "category_counts.plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette(\"Set3\", len(category_counts)))\n",
        "plt.title('Food Category Distribution (South Indian)')\n",
        "plt.ylabel('')\n",
        "plt.show()\n",
        "\n",
        "# 3. Scatter Plot: Calories vs Serving Size\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1401ec0e-c569-4407-b318-0d2f6e5bb839",
      "metadata": {
        "id": "1401ec0e-c569-4407-b318-0d2f6e5bb839"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Create a 2x4 grid for the images\n",
        "rows, cols = 2, 4\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, 8))\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through the images and display them\n",
        "for i, path in enumerate(image_paths):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image in the corresponding subplot\n",
        "    axes[i].imshow(img_rgb)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(f\"Image {i+1}\")  # Optional title\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(len(image_paths), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f791935a-b1b2-4569-86da-e301ab308c87",
      "metadata": {
        "id": "f791935a-b1b2-4569-86da-e301ab308c87"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# List of image labels (names)\n",
        "image_labels = [\n",
        "    \"Dosa\", \"Biryani\", \"Idly\", \"Pongal\", \"Chicken\", \"Fish\", \"Unniappam\", \"Kurma\"\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Create a 2x4 grid for the images\n",
        "rows, cols = 2, 4\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, 8))\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through the images and display them\n",
        "for i, (path, label) in enumerate(zip(image_paths, image_labels)):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image in the corresponding subplot\n",
        "    axes[i].imshow(img_rgb)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(label)  # Use the label as the title\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(len(image_paths), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97adf1a6-82dd-487b-bb8d-992d6c57eac7",
      "metadata": {
        "id": "97adf1a6-82dd-487b-bb8d-992d6c57eac7"
      },
      "outputs": [],
      "source": [
        "pip install numpy opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3f09ce-f8f3-4751-97d4-b44f10ff1707",
      "metadata": {
        "id": "5f3f09ce-f8f3-4751-97d4-b44f10ff1707"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# List of image labels (names)\n",
        "image_labels = [\n",
        "    \"Dosa\", \"Biryani\", \"Idly\", \"Pongal\", \"Chicken\", \"Fish\", \"Unniappam\", \"Kurma\"\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Normalization parameters (mean and std for each channel)\n",
        "mean = [0.485, 0.456, 0.406]  # Example mean (ImageNet standards)\n",
        "std = [0.229, 0.224, 0.225]  # Example std (ImageNet standards)\n",
        "\n",
        "# Create a 2x4 grid for the images\n",
        "rows, cols = 2, 4\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, 8))\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through the images and normalize them\n",
        "for i, (path, label) in enumerate(zip(image_paths, image_labels)):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Normalize the image\n",
        "    img_rgb = img_rgb / 255.0  # Scale to [0, 1]\n",
        "    img_normalized = (img_rgb - mean) / std  # Normalize using mean and std\n",
        "\n",
        "    # Convert back to [0, 1] range for visualization (denormalize)\n",
        "    img_display = (img_normalized * std) + mean\n",
        "    img_display = np.clip(img_display, 0, 1)  # Ensure values are within [0, 1]\n",
        "\n",
        "    # Display the normalized image in the corresponding subplot\n",
        "    axes[i].imshow(img_display)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(label)  # Use the label as the title\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(len(image_paths), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22f8eb1-5874-4cea-afa6-38e8f573feab",
      "metadata": {
        "id": "f22f8eb1-5874-4cea-afa6-38e8f573feab"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Define data augmentation transformations\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),  # Resize to a fixed size\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally with 50% probability\n",
        "    transforms.RandomRotation(degrees=15),  # Rotate randomly within Â±15 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
        "    transforms.RandomCrop(size=(150, 150)),  # Randomly crop a region of the image\n",
        "])\n",
        "\n",
        "# Example image path\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(image_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "img_pil = Image.fromarray(img_rgb)  # Convert to PIL format\n",
        "\n",
        "# Apply data augmentation\n",
        "augmented_images = [augmentation_transform(img_pil) for _ in range(5)]  # Generate 5 augmented versions\n",
        "\n",
        "# Display the original and augmented images\n",
        "fig, axes = plt.subplots(1, 6, figsize=(18, 6))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title(\"Original\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "for i, aug_img in enumerate(augmented_images):\n",
        "    axes[i + 1].imshow(aug_img)\n",
        "    axes[i + 1].set_title(f\"Augmented {i + 1}\")\n",
        "    axes[i + 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e22b83c-f718-4df7-8938-f805882a63ce",
      "metadata": {
        "id": "1e22b83c-f718-4df7-8938-f805882a63ce"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9889bc6b-cf3c-4509-8548-5a1fe4b4289a",
      "metadata": {
        "id": "9889bc6b-cf3c-4509-8548-5a1fe4b4289a"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "report = classification_report(y_test, y_pred, target_names=data.target_names)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e63b780b-394c-409f-9dc8-abed4f226b63",
      "metadata": {
        "id": "e63b780b-394c-409f-9dc8-abed4f226b63"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Re-split the data with a different random seed\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb19f70-4856-4676-8364-ea2dbf490926",
      "metadata": {
        "id": "cfb19f70-4856-4676-8364-ea2dbf490926"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Add noise to the training data\n",
        "X_train_noisy = X_train + np.random.normal(0, 0.1, X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8b4482a-0e69-4b36-a1b8-a0ba3bb6886e",
      "metadata": {
        "id": "b8b4482a-0e69-4b36-a1b8-a0ba3bb6886e"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Use a simpler model\n",
        "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef6b434-5ea7-4840-bda9-fc83a3d08aea",
      "metadata": {
        "id": "3ef6b434-5ea7-4840-bda9-fc83a3d08aea"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Add noise to features\n",
        "np.random.seed(42)\n",
        "X_noisy = X + np.random.normal(0, 0.2, X.shape)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_noisy, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(max_depth=3, n_estimators=50, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e00560-3acc-4077-a4b1-0cb8fae7f7ca",
      "metadata": {
        "id": "e3e00560-3acc-4077-a4b1-0cb8fae7f7ca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data inferred from the chart\n",
        "data = {\n",
        "    \"Food Item\": [\n",
        "        \"Dosa\", \"Idli\", \"Sambar\", \"Vada\", \"Pongal\", \"Biryani\",\n",
        "        \"Uttapam\", \"Rava Kesari\", \"Masala Dosa\", \"Appam\",\n",
        "        \"Chettinad Curry\", \"Pesarattu\", \"Puliyodarai\", \"Curd Rice\"\n",
        "    ],\n",
        "    \"Calories\": [\n",
        "        100, 50, 150, 200, 350, 300, 250, 300, 200, 400,\n",
        "        450, 300, 350, 250\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table to the user\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Calories per South Indian Food Item\", dataframe=df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8051dbaa-7016-48dd-98bb-7c96f3bc8d04",
      "metadata": {
        "id": "8051dbaa-7016-48dd-98bb-7c96f3bc8d04"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a sample dataset for calorie estimation of South Indian food using CNN\n",
        "data = {\n",
        "    \"Food Item\": [\n",
        "        \"Dosa\", \"Idli\", \"Vada\", \"Sambar\", \"Pongal\", \"Uttapam\",\n",
        "        \"Rava Kesari\", \"Masala Dosa\", \"Appam\", \"Chettinad Curry\",\n",
        "        \"Pesarattu\", \"Puliyodarai\", \"Curd Rice\"\n",
        "    ],\n",
        "    \"Calories (per 100g)\": [\n",
        "        133, 97, 220, 50, 190, 230,\n",
        "        320, 165, 150, 200, 170, 180, 120\n",
        "    ],\n",
        "    \"Protein (g)\": [\n",
        "        2.7, 2.1, 4.2, 2.4, 4.5, 5.2,\n",
        "        5.1, 3.5, 2.6, 10.0, 6.8, 5.0, 3.2\n",
        "    ],\n",
        "    \"Carbs (g)\": [\n",
        "        18.8, 22.1, 25.3, 8.8, 27.6, 30.0,\n",
        "        41.0, 20.0, 16.5, 14.0, 25.0, 20.0, 17.0\n",
        "    ],\n",
        "    \"Fats (g)\": [\n",
        "        4.2, 1.2, 12.3, 1.2, 7.5, 8.5,\n",
        "        15.0, 7.0, 5.0, 10.0, 3.0, 6.0, 4.5\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the dataset to the user\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Sample South Indian Food Dataset for CNN\", dataframe=df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5b8d74-aaa8-4887-aee2-458c2fe2dc26",
      "metadata": {
        "id": "5a5b8d74-aaa8-4887-aee2-458c2fe2dc26"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sorting the data for better visualization\n",
        "expanded_df_sorted = expanded_df.sort_values(by=\"Calories (per 100g)\", ascending=False)\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(expanded_df_sorted[\"Food Item\"], expanded_df_sorted[\"Calories (per 100g)\"], color='skyblue')\n",
        "plt.xlabel(\"Calories (per 100g)\")\n",
        "plt.ylabel(\"Food Item\")\n",
        "plt.title(\"Calories in South Indian Food Items\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0214b8-7b41-4a43-830e-2d10a519ccb9",
      "metadata": {
        "id": "bc0214b8-7b41-4a43-830e-2d10a519ccb9"
      },
      "outputs": [],
      "source": [
        "# Recreating the expanded dataset for visualization due to NameError\n",
        "data_combined = {\n",
        "    \"Food Item\": [\n",
        "        \"Dosa\", \"Idli\", \"Vada\", \"Sambar\", \"Pongal\", \"Uttapam\",\n",
        "        \"Rava Kesari\", \"Masala Dosa\", \"Appam\", \"Chettinad Curry\",\n",
        "        \"Pesarattu\", \"Puliyodarai\", \"Curd Rice\", \"Rasam\", \"Avial\",\n",
        "        \"Vegetable Kurma\", \"Kootu\", \"Puli Kuzhambu\", \"Payasam\",\n",
        "        \"Banana Chips\", \"Onion Pakoda\", \"Sweet Pongal\", \"Vegetable Stew\",\n",
        "        \"Neer Dosa\", \"Coconut Chutney\", \"Tomato Rice\", \"Lemon Rice\",\n",
        "        \"Egg Curry\", \"Fish Curry\"\n",
        "    ],\n",
        "    \"Calories (per 100g)\": [\n",
        "        133, 97, 220, 50, 190, 230,\n",
        "        320, 165, 150, 200, 170, 180, 120, 40, 90,\n",
        "        120, 80, 60, 300, 550, 480, 330, 100,\n",
        "        130, 150, 190, 170, 150, 200\n",
        "    ],\n",
        "    \"Protein (g)\": [\n",
        "        2.7, 2.1, 4.2, 2.4, 4.5, 5.2,\n",
        "        5.1, 3.5, 2.6, 10.0, 6.8, 5.0, 3.2, 1.5, 2.0,\n",
        "        3.0, 2.5, 1.0, 3.2, 3.5, 4.8, 6.0, 2.5,\n",
        "        2.0, 2.8, 4.0, 4.2, 6.5, 8.0\n",
        "    ],\n",
        "    \"Carbs (g)\": [\n",
        "        18.8, 22.1, 25.3, 8.8, 27.6, 30.0,\n",
        "        41.0, 20.0, 16.5, 14.0, 25.0, 20.0, 17.0, 6.0, 10.0,\n",
        "        12.0, 8.0, 5.0, 55.0, 50.0, 40.0, 60.0, 10.0,\n",
        "        20.0, 8.0, 25.0, 22.0, 3.0, 5.0\n",
        "    ],\n",
        "    \"Fats (g)\": [\n",
        "        4.2, 1.2, 12.3, 1.2, 7.5, 8.5,\n",
        "        15.0, 7.0, 5.0, 10.0, 3.0, 6.0, 4.5, 0.8, 4.0,\n",
        "        6.0, 3.0, 2.5, 10.0, 40.0, 35.0, 15.0, 5.0,\n",
        "        5.0, 13.0, 6.0, 5.5, 10.0, 12.0\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Recreating DataFrame\n",
        "expanded_df = pd.DataFrame(data_combined)\n",
        "\n",
        "# Sorting for visualization\n",
        "expanded_df_sorted = expanded_df.sort_values(by=\"Calories (per 100g)\", ascending=False)\n",
        "\n",
        "# Visualizing the dataset again\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(expanded_df_sorted[\"Food Item\"], expanded_df_sorted[\"Calories (per 100g)\"], color='skyblue')\n",
        "plt.xlabel(\"Calories (per 100g)\")\n",
        "plt.ylabel(\"Food Item\")\n",
        "plt.title(\"Calories in South Indian Food Items\", fontsize=18)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e50676b-ba3f-49c1-bf60-cf896399723e",
      "metadata": {
        "id": "1e50676b-ba3f-49c1-bf60-cf896399723e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"C:\\\\Users\\\\Bala\\\\Downloads\\\\Expanded_South_Indian_Food_Dataset_for_CNN.csv\")\n",
        "# Summary statistics for calorie content\n",
        "calorie_summary = df[\"Calories (per 100g)\"].describe()\n",
        "\n",
        "# Plotting calorie content trends\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Box plot to visualize calorie distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.boxplot(df[\"Calories (per 100g)\"])\n",
        "plt.title(\"Calorie Content Distribution\")\n",
        "plt.ylabel(\"Calories (per 100g)\")\n",
        "\n",
        "# Histogram to visualize calorie content frequencies\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df[\"Calories (per 100g)\"], bins=10, color='skyblue', edgecolor='black')\n",
        "plt.title(\"Calorie Content Frequency\")\n",
        "plt.xlabel(\"Calories (per 100g)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Return summary statistics for user\n",
        "calorie_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2918ccc4-86b4-48e7-a50c-840e7f47a19a",
      "metadata": {
        "id": "2918ccc4-86b4-48e7-a50c-840e7f47a19a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the AlexNet architecture\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  # Conv1\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),  # Conv2\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),  # Conv3\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),  # Conv4\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),  # Conv5\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),  # Fully connected layer 1\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),  # Fully connected layer 2\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),  # Output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 10  # Example for 10 food categories\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "# Data Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),  # AlexNet requires 227x227 images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Datasets (replace with your dataset path)\n",
        "train_dataset = datasets.FakeData(transform=transform)  # Replace with real dataset\n",
        "test_dataset = datasets.FakeData(transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Model, Loss, Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AlexNet(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7058d6e-2e59-4f92-8eab-71f016db3aa5",
      "metadata": {
        "id": "d7058d6e-2e59-4f92-8eab-71f016db3aa5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Initialize CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))  # 64x64 image, 3 channels (RGB)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout for regularization\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(num_classes, activation='softmax'))  # 'num_classes' is the number of food categories\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f7247c-254a-4637-ba88-eb66ed684a87",
      "metadata": {
        "id": "e8f7247c-254a-4637-ba88-eb66ed684a87"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,      # Normalize image pixels to the range [0, 1]\n",
        "    rotation_range=40,      # Random rotations\n",
        "    width_shift_range=0.2,  # Random width shifts\n",
        "    height_shift_range=0.2, # Random height shifts\n",
        "    shear_range=0.2,        # Shear images\n",
        "    zoom_range=0.2,         # Random zoom\n",
        "    horizontal_flip=True,   # Random horizontal flip\n",
        "    fill_mode='nearest'     # Fill pixels that are empty after transformation\n",
        ")\n",
        "\n",
        "# Flowing images in batches\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',         # Training data directory\n",
        "    target_size=(64, 64), # Resize images to 64x64\n",
        "    batch_size=32,        # Number of images in each batch\n",
        "    class_mode='categorical'  # Use categorical labels\n",
        ")\n",
        "\n",
        "# Validation generator with rescaling only\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    'data/valid',        # Validation data directory\n",
        "    target_size=(64, 64), # Resize images to 64x64\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc416611-8b2b-4f3e-998f-20b1eb3f3a86",
      "metadata": {
        "id": "cc416611-8b2b-4f3e-998f-20b1eb3f3a86"
      },
      "outputs": [],
      "source": [
        "# Example with the correct paths to the data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '\"C:\\\\Users\\\\Bala\\\\Downloads\\\\Expanded_South_Indian_Food_Dataset_for_CNN.csv\"/train',         # Training data directory\n",
        "    target_size=(64, 64),              # Resize images to 64x64\n",
        "    batch_size=32,                     # Number of images in each batch\n",
        "    class_mode='categorical'           # Use categorical labels\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    '\"C:\\\\Users\\\\Bala\\\\Downloads\\\\Expanded_South_Indian_Food_Dataset_for_CNN.csv\"/valid',         # Validation data directory\n",
        "    target_size=(64, 64),              # Resize images to 64x64\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '\"C:\\\\Users\\\\Bala\\\\Downloads\\\\Expanded_South_Indian_Food_Dataset_for_CNN.csv\"/test',          # Test data directory\n",
        "    target_size=(64, 64),              # Resize images to 64x64\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f458fd-d675-40f3-9199-c3337d1f8ab2",
      "metadata": {
        "id": "a1f458fd-d675-40f3-9199-c3337d1f8ab2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =  r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "print(f\"Predicted Calorie Count: {calories[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b5238b-78b9-4c9d-897b-f6945524acb3",
      "metadata": {
        "id": "23b5238b-78b9-4c9d-897b-f6945524acb3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =  r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))  # Resize image to 64x64\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "predicted_calories = calories[0][0]  # Get the predicted calorie value\n",
        "\n",
        "# Print the predicted calorie count\n",
        "print(f\"Predicted Calorie Count: {predicted_calories}\")\n",
        "\n",
        "# Display the image with the predicted calorie value\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.title(f\"Predicted Calorie: {predicted_calories:.2f} kcal\")  # Title with calorie value\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de02d2a8-6db6-4d71-9633-75b8abc2029b",
      "metadata": {
        "id": "de02d2a8-6db6-4d71-9633-75b8abc2029b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =   r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))  # Resize image to 64x64\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "predicted_calories = calories[0][0]  # Get the predicted calorie value\n",
        "\n",
        "# Print the predicted calorie count\n",
        "print(f\"Predicted Calorie Count: {predicted_calories}\")\n",
        "\n",
        "# Display the image with the predicted calorie value\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.title(f\"Predicted Calorie: {predicted_calories:.2f} kcal\")  # Title with calorie value\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9854b22-b92d-4bbc-8c0b-36c86aeacadb",
      "metadata": {
        "id": "b9854b22-b92d-4bbc-8c0b-36c86aeacadb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))  # Resize image to 64x64\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "predicted_calories = calories[0][0]  # Get the predicted calorie value\n",
        "\n",
        "# Print the predicted calorie count\n",
        "print(f\"Predicted Calorie Count: {predicted_calories}\")\n",
        "\n",
        "# Display the image with the predicted calorie value\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.title(f\"Predicted Calorie: {predicted_calories:.2f} kcal\")  # Title with calorie value\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00582ee1-db15-450b-9eaf-35669bfb9d3b",
      "metadata": {
        "id": "00582ee1-db15-450b-9eaf-35669bfb9d3b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =     r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))  # Resize image to 64x64\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "predicted_calories = calories[0][0]  # Get the predicted calorie value\n",
        "\n",
        "# Print the predicted calorie count\n",
        "print(f\"Predicted Calorie Count: {predicted_calories}\")\n",
        "\n",
        "# Display the image with the predicted calorie value\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.title(f\"Predicted Calorie: {predicted_calories:.2f} kcal\")  # Title with calorie value\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3572f6-e6ac-45c0-b29f-eb79886b310a",
      "metadata": {
        "id": "9f3572f6-e6ac-45c0-b29f-eb79886b310a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))  # Resize image to 64x64\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "predicted_calories = calories[0][0]  # Get the predicted calorie value\n",
        "\n",
        "# Print the predicted calorie count\n",
        "print(f\"Predicted Calorie Count: {predicted_calories}\")\n",
        "\n",
        "# Display the image with the predicted calorie value\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.title(f\"Predicted Calorie: {predicted_calories:.2f} kcal\")  # Title with calorie value\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48c9b6d-4d30-4801-80c4-2cddb37f597f",
      "metadata": {
        "id": "f48c9b6d-4d30-4801-80c4-2cddb37f597f"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path =    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"  # Path to a new food image\n",
        "img = image.load_img(img_path, target_size=(64, 64))  # Resize image to 64x64\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Predict the calorie value\n",
        "calories = model.predict(img_array)\n",
        "predicted_calories = calories[0][0]  # Get the predicted calorie value\n",
        "\n",
        "# Print the predicted calorie count\n",
        "print(f\"Predicted Calorie Count: {predicted_calories}\")\n",
        "\n",
        "# Display the image with the predicted calorie value\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.title(f\"Predicted Calorie: {predicted_calories:.2f} kcal\")  # Title with calorie value\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b3dfb4-eb49-458a-a667-65d3c8e71432",
      "metadata": {
        "id": "c0b3dfb4-eb49-458a-a667-65d3c8e71432"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model('your_trained_model.h5')\n",
        "\n",
        "# List of image paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Process each image\n",
        "for img_path in image_paths:\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(64, 64))  # Resize to 64x64\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Normalize the image\n",
        "\n",
        "    # Predict the calorie value\n",
        "    calories = model.predict(img_array)\n",
        "\n",
        "    # Display the image and predicted calorie count\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Calorie Count: {calories[0][0]:.2f} kcal\")\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb767a2-9005-4d93-9a27-d23764ecaab6",
      "metadata": {
        "id": "cbb767a2-9005-4d93-9a27-d23764ecaab6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model(r\"C:\\Users\\Bala\\Desktop\\Indian Food Images.h5\")  # Replace with your model path\n",
        "\n",
        "# List of image paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Process each image\n",
        "for img_path in image_paths:\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(64, 64))  # Resize to 64x64\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Normalize the image\n",
        "\n",
        "    # Predict the calorie value\n",
        "    calories = model.predict(img_array)\n",
        "\n",
        "    # Display the image and predicted calorie count\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Calorie Count: {calories[0][0]:.2f} kcal\")\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74244e7b-7b68-4d81-816a-a0089c2ff2e2",
      "metadata": {
        "id": "74244e7b-7b68-4d81-816a-a0089c2ff2e2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the trained model (if available)\n",
        "# Make sure to replace 'your_trained_model.h5' with the actual model path\n",
        "# model = load_model('your_trained_model.h5')\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Create a 2x4 grid for the images\n",
        "rows, cols = 2, 4\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, 8))\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through the images and display them\n",
        "for i, path in enumerate(image_paths):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image in the corresponding subplot\n",
        "    axes[i].imshow(img_rgb)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(f\"Image {i+1}\")  # Optional title\n",
        "\n",
        "    # Predict calorie count (if model is loaded)\n",
        "    # img_array = image.img_to_array(img_resized)  # Convert image to array\n",
        "    # img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    # img_array /= 255.0  # Normalize the image\n",
        "\n",
        "    # If model is available, predict calorie content\n",
        "    # calorie_prediction = model.predict(img_array)\n",
        "    # axes[i].set_title(f\"Image {i+1}\\nCalories: {calorie_prediction[0][0]:.2f} kcal\")\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(len(image_paths), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "422377f5-85bd-4b35-9868-70bd71ef60d5",
      "metadata": {
        "id": "422377f5-85bd-4b35-9868-70bd71ef60d5"
      },
      "outputs": [],
      "source": [
        "img_array = image.img_to_array(img_resized)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# If model is available, predict calorie content\n",
        "calorie_prediction = model.predict(img_array)\n",
        "axes[i].set_title(f\"Image {i+1}\\nCalories: {calorie_prediction[0][0]:.2f} kcal\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4409c154-93df-49ad-804c-9bdac038d2e2",
      "metadata": {
        "id": "4409c154-93df-49ad-804c-9bdac038d2e2"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Example: Load an image\n",
        "image_path =  r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77678d1c-75cb-4ae5-b35a-f7f79e3f154a",
      "metadata": {
        "id": "77678d1c-75cb-4ae5-b35a-f7f79e3f154a"
      },
      "outputs": [],
      "source": [
        "# Resize image to 224x224 pixels\n",
        "image = image.resize((224, 224))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4cce2ad-a0a9-4505-80b1-a3b7314e8bc5",
      "metadata": {
        "id": "c4cce2ad-a0a9-4505-80b1-a3b7314e8bc5"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define a transformation pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Apply transformations\n",
        "image_tensor = transform(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2bc1ad-6091-4547-9cb1-ae9d2ec66827",
      "metadata": {
        "id": "ff2bc1ad-6091-4547-9cb1-ae9d2ec66827"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example: Split dataset\n",
        "image_paths = [ r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\", r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\", r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\", ...]\n",
        "train_paths, temp_paths = train_test_split(image_paths, test_size=0.3, random_state=42)\n",
        "val_paths, test_paths = train_test_split(temp_paths, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed375d6-bf74-4a61-8f0d-ed0d1fd518dc",
      "metadata": {
        "id": "eed375d6-bf74-4a61-8f0d-ed0d1fd518dc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"C:\\\\Users\\\\Bala\\\\Downloads\\\\south_indian_food_dataset.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows to understand the dataset\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc101674-b824-42c1-8901-4a04a6e031ef",
      "metadata": {
        "id": "bc101674-b824-42c1-8901-4a04a6e031ef"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"C:\\\\Users\\\\Bala\\\\Downloads\\\\south_indian_food_dataset.csv\")\n",
        "\n",
        "# Feature Engineering\n",
        "# Encode categorical column 'Tags'\n",
        "data['Tags_Encoded'] = data['Tags'].astype('category').cat.codes\n",
        "\n",
        "# Features and target variable\n",
        "X = data[['Calories_Estimated', 'Tags_Encoded']]\n",
        "y = data['Calories_Estimated']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Support Vector Machine\": SVR()\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"R2 Score\": r2\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(results_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f55ca6a-59d0-434f-8f2e-d31c33c583a7",
      "metadata": {
        "id": "0f55ca6a-59d0-434f-8f2e-d31c33c583a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualization: Predicted vs Actual\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "plt.title(\"Predicted vs Actual Calorie Values\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Bar chart for performance metrics\n",
        "results_df.plot(kind='bar', figsize=(12, 8), title=\"Model Performance Comparison\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5844e302-9adb-4493-8bc4-dc35ba5102b8",
      "metadata": {
        "id": "5844e302-9adb-4493-8bc4-dc35ba5102b8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50, MobileNetV2\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"C:\\\\Users\\\\Bala\\\\Downloads\\\\south_indian_food_dataset.csv\")\n",
        "\n",
        "# Feature Engineering\n",
        "# Encode categorical column 'Tags'\n",
        "data['Tags_Encoded'] = data['Tags'].astype('category').cat.codes\n",
        "\n",
        "# Assuming images are in a directory and 'Image_Name' contains filenames\n",
        "# Set image directory path\n",
        "image_dir = \"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\"\n",
        "\n",
        "# Image preprocessing\n",
        "def preprocess_image(file_name):\n",
        "    img_path = image_dir + file_name\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    return img_array\n",
        "\n",
        "# Load image data\n",
        "image_data = np.array([preprocess_image(name) for name in data[\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\istockphoto-678434780-612x612.jpg\"]])\n",
        "image_data = image_data / 255.0  # Normalize pixel values\n",
        "\n",
        "# Features and target variable\n",
        "X = image_data\n",
        "y = data['Calories_Estimated']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert targets to numpy arrays\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Initialize pre-trained models\n",
        "models = {\n",
        "    \"ResNet50\": ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
        "    \"MobileNetV2\": MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, base_model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=10,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Store results\n",
        "    results[model_name] = {\n",
        "        \"Loss\": test_loss,\n",
        "        \"MAE\": test_mae\n",
        "    }\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(results_df)\n",
        "\n",
        "# Visualization: Bar chart for performance metrics\n",
        "results_df.plot(kind='bar', figsize=(12, 8), title=\"Model Performance Comparison\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae9e57c-9d54-46f0-a2f6-2e62d33d2242",
      "metadata": {
        "id": "bae9e57c-9d54-46f0-a2f6-2e62d33d2242"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "data = {\n",
        "    'Image Filename': ['dosa1.jpg', 'idli1.jpg', 'sambar1.jpg', 'vada1.jpg', 'pongal1.jpg',\n",
        "                       'biryani1.jpg', 'uttapam1.jpg', 'ravakesari1.jpg', 'masaladosa1.jpg',\n",
        "                       'appam1.jpg', 'chettinadcurry1.jpg', 'pesarattu1.jpg', 'puliyodarai1.jpg',\n",
        "                       'curdrice1.jpg'],\n",
        "    'Food Item': ['Dosa', 'Idli', 'Sambar', 'Vada', 'Pongal', 'Biryani', 'Uttapam', 'Rava Kesari',\n",
        "                  'Masala Dosa', 'Appam', 'Chettinad Curry', 'Pesarattu', 'Puliyodarai', 'Curd Rice'],\n",
        "    'Category': ['Breakfast', 'Breakfast', 'Soup', 'Snack', 'Breakfast', 'Main Course', 'Breakfast',\n",
        "                 'Dessert', 'Snack', 'Breakfast', 'Main Course', 'Breakfast', 'Main Course', 'Side Dish'],\n",
        "    'Calories': [120, 39, 150, 180, 350, 250, 150, 200, 350, 150, 450, 250, 300, 150],\n",
        "    'Serving Size (g)': [150, 100, 200, 100, 200, 300, 150, 100, 200, 120, 250, 150, 200, 200]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert 'Category' to numeric labels for classification\n",
        "label_encoder = LabelEncoder()\n",
        "df['Category_Label'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# Split the data into training and testing\n",
        "X = df[['Calories', 'Serving Size (g)']]  # Features\n",
        "y = df['Category_Label']  # Labels (Categories)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Dummy predictions for demonstration (usually you'd use a model to predict)\n",
        "# In practice, replace this with the model's predicted values\n",
        "y_pred = y_test  # For simplicity, using true labels as predicted values\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix for Food Category Classification')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df7cb0ed-45d5-4769-97ea-eb41a34ea90e",
      "metadata": {
        "id": "df7cb0ed-45d5-4769-97ea-eb41a34ea90e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970f3ce2-bf88-4b61-9d0e-d6188c396a90",
      "metadata": {
        "id": "970f3ce2-bf88-4b61-9d0e-d6188c396a90"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Dosa nutritional values\n",
        "protein = 3  # grams\n",
        "fat = 5      # grams\n",
        "carbs = 20   # grams\n",
        "\n",
        "# Calorie calculation formula\n",
        "calories = (protein * 4) + (fat * 9) + (carbs * 4)\n",
        "\n",
        "# Image path (update this with the correct path to your image)\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"  # Replace with the actual path to your image\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image and calorie details\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Dosa\\nCalories: {calories} kcal\\nProtein: {protein} g, Fat: {fat} g, Carbs: {carbs} g\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c068f6-ceb4-4a36-9cf8-15e1e3cf57be",
      "metadata": {
        "id": "85c068f6-ceb4-4a36-9cf8-15e1e3cf57be"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Dosa nutritional values\n",
        "protein = 2  # grams\n",
        "fat = 1      # grams\n",
        "carbs = 8   # grams\n",
        "\n",
        "# Calorie calculation formula\n",
        "calories = (protein * 4) + (fat * 9) + (carbs * 4)\n",
        "\n",
        "# Image path (update this with the correct path to your image)\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\"  # Replace with the actual path to your image\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image and calorie details\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(f\"IDLI\\nCalories: {calories} kcal\\nProtein: {protein} g, Fat: {fat} g, Carbs: {carbs} g\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a6e6939-c756-4ed9-9184-019be7efba57",
      "metadata": {
        "id": "7a6e6939-c756-4ed9-9184-019be7efba57"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "586a4be4-acb7-4366-9f42-cf7a866dda6a",
      "metadata": {
        "id": "586a4be4-acb7-4366-9f42-cf7a866dda6a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Example ground truth labels (actual categories)\n",
        "true_labels = [\n",
        "    \"Breakfast\", \"Breakfast\", \"Soup\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Dessert\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Main Course\", \"Side Dish\"\n",
        "]\n",
        "\n",
        "# Simulated predictions from your ML model (predicted categories with a few mismatches)\n",
        "predicted_labels = [\n",
        "    \"Breakfast\", \"Breakfast\", \"Snack\", \"Snack\", \"Breakfast\",  # Mismatch at index 2\n",
        "    \"Main Course\", \"Breakfast\", \"Dessert\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Side Dish\", \"Side Dish\"  # Mismatch at index 12\n",
        "]\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels, zero_division=0))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e110fcf3-0044-45a1-9a7d-2ebcdaa27952",
      "metadata": {
        "id": "e110fcf3-0044-45a1-9a7d-2ebcdaa27952"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset with loss and accuracy values\n",
        "data = {\n",
        "    \"Image Filename\": [\n",
        "        \"dosa1.jpg\", \"idli1.jpg\", \"sambar1.jpg\", \"vada1.jpg\",\n",
        "        \"pongal1.jpg\", \"biryani1.jpg\", \"uttapam1.jpg\", \"ravakesari1.jpg\",\n",
        "        \"masaladosa1.jpg\", \"appam1.jpg\", \"chettinadcurry1.jpg\",\n",
        "        \"pesarattu1.jpg\", \"puliyodarai1.jpg\", \"curdrice1.jpg\"\n",
        "    ],\n",
        "    \"Food Item\": [\n",
        "        \"Dosa\", \"Idli\", \"Sambar\", \"Vada\", \"Pongal\", \"Biryani\", \"Uttapam\",\n",
        "        \"Rava Kesari\", \"Masala Dosa\", \"Appam\", \"Chettinad Curry\",\n",
        "        \"Pesarattu\", \"Puliyodarai\", \"Curd Rice\"\n",
        "    ],\n",
        "    \"Loss\": np.random.uniform(0.1, 0.5, 14),  # Simulated loss values\n",
        "    \"Accuracy\": np.random.uniform(0.85, 0.95, 14),  # Simulated accuracy values\n",
        "}\n",
        "\n",
        "# Convert data into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table\n",
        "print(\"Loss and Accuracy Table:\")\n",
        "print(df)\n",
        "\n",
        "# Plot Loss and Accuracy graphs\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Loss Graph\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(df[\"Image Filename\"], df[\"Loss\"], marker='o', color='r', label=\"Loss\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Loss per Food Item\")\n",
        "plt.xlabel(\"Food Item\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49bc0181-a407-441f-8780-a0707e78193b",
      "metadata": {
        "id": "49bc0181-a407-441f-8780-a0707e78193b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "# Accuracy Graph\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(df[\"Image Filename\"], df[\"Accuracy\"], marker='o', color='g', label=\"Accuracy\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Accuracy per Food Item\")\n",
        "plt.xlabel(\"Food Item\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d97c3d-a736-4724-9e3a-8e8e3901d4df",
      "metadata": {
        "id": "00d97c3d-a736-4724-9e3a-8e8e3901d4df"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "data = {\n",
        "    'Food Item': ['Dosa', 'Idli', 'Sambar', 'Vada', 'Pongal', 'Biryani', 'Uttapam', 'Rava Kesari', 'Masala Dosa', 'Appam', 'Chettinad Curry', 'Pesarattu', 'Puliyodarai', 'Curd Rice'],\n",
        "    'Calories': [120, 39, 150, 180, 350, 250, 150, 200, 350, 150, 450, 250, 300, 150],\n",
        "    'Protein (g)': [3, 2, 5, 6, 10, 8, 6, 2, 6, 3, 10, 10, 6, 6],\n",
        "    'Fat (g)': [5, 1, 3, 10, 15, 12, 8, 10, 15, 3, 20, 10, 12, 8],\n",
        "    'Carbs (g)': [20, 8, 12, 15, 50, 60, 20, 30, 50, 20, 40, 20, 60, 30],\n",
        "    'Category': ['Breakfast', 'Breakfast', 'Soup', 'Snack', 'Breakfast', 'Main Course', 'Breakfast', 'Dessert', 'Breakfast', 'Breakfast', 'Main Course', 'Breakfast', 'Main Course', 'Side Dish']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = df[['Calories', 'Protein (g)', 'Fat (g)', 'Carbs (g)']]\n",
        "y = df['Category']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a7c790-755b-4e07-9f67-3f31f11be978",
      "metadata": {
        "id": "e1a7c790-755b-4e07-9f67-3f31f11be978"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "data = {\n",
        "    'Food Item': ['Dosa', 'Idli', 'Sambar', 'Vada', 'Pongal', 'Biryani', 'Uttapam', 'Rava Kesari', 'Masala Dosa', 'Appam', 'Chettinad Curry', 'Pesarattu', 'Puliyodarai', 'Curd Rice'],\n",
        "    'Calories': [120, 39, 150, 180, 350, 250, 150, 200, 350, 150, 450, 250, 300, 150],\n",
        "    'Protein (g)': [3, 2, 5, 6, 10, 8, 6, 2, 6, 3, 10, 10, 6, 6],\n",
        "    'Fat (g)': [5, 1, 3, 10, 15, 12, 8, 10, 15, 3, 20, 10, 12, 8],\n",
        "    'Carbs (g)': [20, 8, 12, 15, 50, 60, 20, 30, 50, 20, 40, 20, 60, 30],\n",
        "    'Category': ['Breakfast', 'Breakfast', 'Soup', 'Snack', 'Breakfast', 'Main Course', 'Breakfast', 'Dessert', 'Breakfast', 'Breakfast', 'Main Course', 'Breakfast', 'Main Course', 'Side Dish']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = df[['Calories', 'Protein (g)', 'Fat (g)', 'Carbs (g)']]\n",
        "y = df['Category']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))  # Adjust the figure size for better clarity\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.xticks(fontsize=10, rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()  # Automatically adjust layout to avoid overlap\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fdf5213-d004-48b3-8f2b-8e4d78a1807c",
      "metadata": {
        "id": "1fdf5213-d004-48b3-8f2b-8e4d78a1807c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image dimensions\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Base directory for your dataset\n",
        "base_dir = r\"C:\\Users\\Bala\\Desktop\\south food\"\n",
        "\n",
        "# Directories for training and validation datasets\n",
        "train_dir = f\"{base_dir}\\\\train\"\n",
        "valid_dir = f\"{base_dir}\\\\valid\"\n",
        "\n",
        "# Data generators for loading and augmenting images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=30,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training data from directory\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "# Flow validation data from directory\n",
        "valid_data = valid_datagen.flow_from_directory(valid_dir,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64639c85-9f75-4063-81ed-bd2104dd1050",
      "metadata": {
        "id": "64639c85-9f75-4063-81ed-bd2104dd1050"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea31023-1236-4e06-8bec-3ee34815b1c5",
      "metadata": {
        "id": "0ea31023-1236-4e06-8bec-3ee34815b1c5"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nXGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9a2ad2-b7c1-44a4-b529-bdb36e63391f",
      "metadata": {
        "id": "bd9a2ad2-b7c1-44a4-b529-bdb36e63391f"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2183771-d609-4843-96c4-abfe9babb9f9",
      "metadata": {
        "id": "e2183771-d609-4843-96c4-abfe9babb9f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nMLP Classification Report:\\n\", classification_report(y_test, y_pred_mlp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a83eb5-d6ee-48b8-bc01-ac5962789528",
      "metadata": {
        "id": "f0a83eb5-d6ee-48b8-bc01-ac5962789528"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nKNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8d767f-7bdf-4211-ba98-7a479af2de63",
      "metadata": {
        "id": "3c8d767f-7bdf-4211-ba98-7a479af2de63"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_classifier = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500, random_state=42)\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "y_pred_logistic = logistic_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_logistic))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c739fa-af0b-4331-a3b6-e75ca6687882",
      "metadata": {
        "id": "20c739fa-af0b-4331-a3b6-e75ca6687882"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern, greycomatrix, greycoprops\n",
        "\n",
        "# Load the image\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert to grayscale\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Compute Canny edges\n",
        "canny_edges = cv2.Canny(image_gray, 100, 200)\n",
        "\n",
        "# Compute Local Binary Pattern (LBP)\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "lbp = local_binary_pattern(image_gray, n_points, radius, method=\"uniform\")\n",
        "\n",
        "# Compute Haralick features (Contrast, Homogeneity, Energy, Correlation)\n",
        "glcm = greycomatrix(image_gray, distances=[5], angles=[0], symmetric=True, normed=True)\n",
        "contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
        "homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
        "energy = greycoprops(glcm, 'energy')[0, 0]\n",
        "correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
        "\n",
        "# Extract Red and Green channels\n",
        "red_channel = image_rgb[:, :, 0]\n",
        "green_channel = image_rgb[:, :, 1]\n",
        "\n",
        "# Plot the results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0, 0].imshow(image_rgb)\n",
        "axes[0, 0].set_title(\"Original Image\")\n",
        "axes[0, 0].axis(\"off\")\n",
        "\n",
        "axes[0, 1].imshow(canny_edges, cmap=\"gray\")\n",
        "axes[0, 1].set_title(\"Canny Edges\")\n",
        "axes[0, 1].axis(\"off\")\n",
        "\n",
        "axes[0, 2].bar(['Contrast', 'Homogeneity', 'Energy', 'Correlation'],\n",
        "               [contrast, homogeneity, energy, correlation])\n",
        "axes[0, 2].set_title(\"Haralick Texture Features\")\n",
        "\n",
        "axes[1, 0].hist(lbp.ravel(), bins=np.arange(0, n_points + 3), density=True)\n",
        "axes[1, 0].set_title(\"LBP Features\")\n",
        "axes[1, 0].set_xlabel(\"Normalized Count\")\n",
        "\n",
        "axes[1, 1].imshow(red_channel, cmap=\"gray\")\n",
        "axes[1, 1].set_title(\"Red Channel\")\n",
        "axes[1, 1].axis(\"off\")\n",
        "\n",
        "axes[1, 2].imshow(green_channel, cmap=\"gray\")\n",
        "axes[1, 2].set_title(\"Green Channel\")\n",
        "axes[1, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f769e8cb-9d3c-4afb-9f58-87b8be517c4d",
      "metadata": {
        "id": "f769e8cb-9d3c-4afb-9f58-87b8be517c4d"
      },
      "outputs": [],
      "source": [
        "pip install mahotas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e01919-fab4-46d9-bfa3-cbbf736ac148",
      "metadata": {
        "id": "b8e01919-fab4-46d9-bfa3-cbbf736ac148"
      },
      "outputs": [],
      "source": [
        "import mahotas\n",
        "\n",
        "# Compute Haralick features\n",
        "haralick_features = mahotas.features.haralick(image_gray).mean(axis=0)\n",
        "\n",
        "# Extract specific features\n",
        "contrast = haralick_features[1]  # Contrast\n",
        "homogeneity = haralick_features[2]  # Homogeneity\n",
        "energy = haralick_features[3]  # Energy\n",
        "correlation = haralick_features[4]  # Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03fd33e6-8806-45e9-bb1c-4c20618cbf28",
      "metadata": {
        "id": "03fd33e6-8806-45e9-bb1c-4c20618cbf28"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "import mahotas\n",
        "\n",
        "# Load the image\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert to grayscale\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Compute Canny edges\n",
        "canny_edges = cv2.Canny(image_gray, 100, 200)\n",
        "\n",
        "# Compute Local Binary Pattern (LBP)\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "lbp = local_binary_pattern(image_gray, n_points, radius, method=\"uniform\")\n",
        "\n",
        "# Compute Haralick features using mahotas\n",
        "haralick_features = mahotas.features.haralick(image_gray).mean(axis=0)\n",
        "contrast = haralick_features[1]  # Contrast\n",
        "homogeneity = haralick_features[2]  # Homogeneity\n",
        "energy = haralick_features[3]  # Energy\n",
        "correlation = haralick_features[4]  # Correlation\n",
        "\n",
        "# Extract Red and Green channels\n",
        "red_channel = image_rgb[:, :, 0]\n",
        "green_channel = image_rgb[:, :, 1]\n",
        "\n",
        "# Plot the results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0, 0].imshow(image_rgb)\n",
        "axes[0, 0].set_title(\"Original Image\")\n",
        "axes[0, 0].axis(\"off\")\n",
        "\n",
        "axes[0, 1].imshow(canny_edges, cmap=\"gray\")\n",
        "axes[0, 1].set_title(\"Canny Edges\")\n",
        "axes[0, 1].axis(\"off\")\n",
        "\n",
        "axes[0, 2].bar(['Contrast', 'Homogeneity', 'Energy', 'Correlation'],\n",
        "               [contrast, homogeneity, energy, correlation])\n",
        "axes[0, 2].set_title(\"Haralick Texture Features\")\n",
        "\n",
        "axes[1, 0].hist(lbp.ravel(), bins=np.arange(0, n_points + 3), density=True)\n",
        "axes[1, 0].set_title(\"LBP Features\")\n",
        "axes[1, 0].set_xlabel(\"Normalized Count\")\n",
        "\n",
        "axes[1, 1].imshow(red_channel, cmap=\"gray\")\n",
        "axes[1, 1].set_title(\"Red Channel\")\n",
        "axes[1, 1].axis(\"off\")\n",
        "\n",
        "axes[1, 2].imshow(green_channel, cmap=\"gray\")\n",
        "axes[1, 2].set_title(\"Green Channel\")\n",
        "axes[1, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "928177bd-120b-4f45-9d14-9522ebf8ad69",
      "metadata": {
        "id": "928177bd-120b-4f45-9d14-9522ebf8ad69"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "img = load_img(image_path)  # Load the image\n",
        "img_array = img_to_array(img)  # Convert the image to a NumPy array\n",
        "img_array = img_array.reshape((1,) + img_array.shape)  # Reshape for ImageDataGenerator\n",
        "\n",
        "# Create an ImageDataGenerator with augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,        # Rotate the image up to 40 degrees\n",
        "    width_shift_range=0.2,    # Shift the image width by a factor of 0.2\n",
        "    height_shift_range=0.2,   # Shift the image height by a factor of 0.2\n",
        "    shear_range=0.2,          # Apply shear transformation\n",
        "    zoom_range=0.2,           # Zoom in/out on the image\n",
        "    horizontal_flip=True,     # Flip the image horizontally\n",
        "    fill_mode='nearest'       # Fill empty pixels after transformation\n",
        ")\n",
        "\n",
        "# Generate augmented images\n",
        "augmented_images = datagen.flow(img_array, batch_size=1)\n",
        "\n",
        "# Plot augmented images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):  # Display 9 augmented images\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    batch = next(augmented_images)  # Generate a batch of images\n",
        "    augmented_image = array_to_img(batch[0])  # Convert to a PIL image\n",
        "    plt.imshow(augmented_image)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28497821-7bd6-4dd9-91f0-c0a70f753333",
      "metadata": {
        "id": "28497821-7bd6-4dd9-91f0-c0a70f753333"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\"\n",
        "]\n",
        "\n",
        "# Create an ImageDataGenerator with augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,        # Rotate the image up to 40 degrees\n",
        "    width_shift_range=0.2,    # Shift the image width by a factor of 0.2\n",
        "    height_shift_range=0.2,   # Shift the image height by a factor of 0.2\n",
        "    shear_range=0.2,          # Apply shear transformation\n",
        "    zoom_range=0.2,           # Zoom in/out on the image\n",
        "    horizontal_flip=True,     # Flip the image horizontally\n",
        "    fill_mode='nearest'       # Fill empty pixels after transformation\n",
        ")\n",
        "\n",
        "# Loop through each image and apply augmentation\n",
        "for image_path in image_paths:\n",
        "    # Load the image\n",
        "    img = load_img(image_path)  # Load the image\n",
        "    img_array = img_to_array(img)  # Convert the image to a NumPy array\n",
        "    img_array = img_array.reshape((1,) + img_array.shape)  # Reshape for ImageDataGenerator\n",
        "\n",
        "    # Generate augmented images\n",
        "    augmented_images = datagen.flow(img_array, batch_size=1)\n",
        "\n",
        "    # Plot augmented images\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.suptitle(f\"Augmented Images for {image_path.split('/')[-1]}\", fontsize=14)\n",
        "    for i in range(9):  # Display 9 augmented images\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        batch = next(augmented_images)  # Generate a batch of images\n",
        "        augmented_image = array_to_img(batch[0])  # Convert to a PIL image\n",
        "        plt.imshow(augmented_image)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c34be1a-0906-45c6-b52b-32213f24b7d5",
      "metadata": {
        "id": "0c34be1a-0906-45c6-b52b-32213f24b7d5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# List of image paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Load and preprocess images\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "images = []\n",
        "labels = []  # Synthetic labels for demonstration\n",
        "\n",
        "for i, path in enumerate(image_paths):\n",
        "    if os.path.exists(path):\n",
        "        img = load_img(path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        images.append(img_array)\n",
        "        labels.append(i % 2)  # Assign synthetic binary labels (e.g., 0 or 1)\n",
        "    else:\n",
        "        print(f\"Image not found: {path}\")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Save metrics for plotting\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24dd03ce-0e11-431b-a8ce-18c432611622",
      "metadata": {
        "id": "24dd03ce-0e11-431b-a8ce-18c432611622"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_accuracy, label='Train Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training vs. Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2824142d-b9a1-4112-a1e6-d6f4e8ec9bc3",
      "metadata": {
        "id": "2824142d-b9a1-4112-a1e6-d6f4e8ec9bc3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training vs. Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd8d89f-b80c-48d3-a626-9fde700a90c6",
      "metadata": {
        "id": "7cd8d89f-b80c-48d3-a626-9fde700a90c6"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d75482-aa32-43bb-aa2d-2fd543dde267",
      "metadata": {
        "id": "50d75482-aa32-43bb-aa2d-2fd543dde267"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y_pred_prob = model.predict(X_test).ravel()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3017bc3b-1ba6-42fe-8e59-a2595c03328a",
      "metadata": {
        "id": "3017bc3b-1ba6-42fe-8e59-a2595c03328a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(recall, precision, label='Precision-Recall Curve')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d87e9d-f487-403f-bad3-421c9a130136",
      "metadata": {
        "id": "46d87e9d-f487-403f-bad3-421c9a130136"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# List of image paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# Load and preprocess images\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
        "images = []\n",
        "labels = []  # Synthetic labels for demonstration\n",
        "\n",
        "for i, path in enumerate(image_paths):\n",
        "    if os.path.exists(path):\n",
        "        img = load_img(path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        images.append(img_array)\n",
        "        labels.append(i % 2)  # Assign synthetic binary labels (e.g., 0 or 1)\n",
        "    else:\n",
        "        print(f\"Image not found: {path}\")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a function to create a deeper CNN model\n",
        "def create_deep_model(base_model):\n",
        "    # Freeze the base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom classification layers\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Instantiate deeper architectures\n",
        "models = {\n",
        "    \"ResNet50\": create_deep_model(ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))),\n",
        "    \"VGG16\": create_deep_model(VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))),\n",
        "    \"InceptionV3\": create_deep_model(InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\\n\")\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=2, verbose=1)\n",
        "    results[name] = {\n",
        "        \"history\": history.history,\n",
        "        \"evaluation\": model.evaluate(X_test, y_test, verbose=0)\n",
        "    }\n",
        "\n",
        "# Display results for each model\n",
        "for name, result in results.items():\n",
        "    print(f\"\\n{name} Evaluation Metrics:\")\n",
        "    print(f\"Loss: {result['evaluation'][0]:.4f}, Accuracy: {result['evaluation'][1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf83b34-8f3c-4002-8c58-05576c12ce4d",
      "metadata": {
        "id": "fdf83b34-8f3c-4002-8c58-05576c12ce4d"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72e21f93-b4ee-4020-b0e6-88929240672c",
      "metadata": {
        "id": "72e21f93-b4ee-4020-b0e6-88929240672c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the sample image for prediction\n",
        "sample_image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "sample_image = load_img(sample_image_path, target_size=(224, 224))  # Resize to model input size\n",
        "sample_image_array = img_to_array(sample_image) / 255.0  # Normalize pixel values\n",
        "\n",
        "# Titles for the models and mock evaluation metrics\n",
        "model_titles = [\"ResNet50\", \"VGG16\", \"InceptionV3\"]\n",
        "evaluation_metrics = [\n",
        "    {\"Loss\": 0.9390, \"Accuracy\": 0.5000},\n",
        "    {\"Loss\": 1.9283, \"Accuracy\": 0.0000},\n",
        "    {\"Loss\": 4.2100, \"Accuracy\": 0.0000},\n",
        "]\n",
        "\n",
        "# Visualization setup\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(sample_image)\n",
        "    ax.set_title(f\"{model_titles[i]}\\nLoss: {evaluation_metrics[i]['Loss']:.4f}, Accuracy: {evaluation_metrics[i]['Accuracy']:.4f}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Visualization of Image Predictions by Different Models\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5588404-9f7f-4df7-bada-58a302962172",
      "metadata": {
        "id": "b5588404-9f7f-4df7-bada-58a302962172"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the sample image\n",
        "sample_image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "sample_image = load_img(sample_image_path, target_size=(224, 224))  # Resize for the model\n",
        "sample_image_array = img_to_array(sample_image) / 255.0  # Normalize the image\n",
        "sample_image_array = np.expand_dims(sample_image_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Use a pretrained ResNet50 model for demonstration\n",
        "model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
        "\n",
        "# Grad-CAM Function\n",
        "def generate_gradcam(input_model, img_array, last_conv_layer_name, pred_index=None):\n",
        "    # Create a model that maps input images to the last conv layer outputs and predictions\n",
        "    grad_model = Model(\n",
        "        inputs=[input_model.inputs],\n",
        "        outputs=[\n",
        "            input_model.get_layer(last_conv_layer_name).output,  # Feature maps\n",
        "            input_model.output,  # Predictions\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Compute the gradient of the top predicted class for the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)  # Get feature maps and predictions\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])  # Use the top predicted class\n",
        "        loss = predictions[:, pred_index]  # Focus on the top predicted class\n",
        "\n",
        "    # Compute gradients with respect to the feature map\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))  # Global average pooling of gradients\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    # Weight the feature map with the pooled gradients\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)  # Remove single-dimensional entries\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)  # Normalize the heatmap\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Generate Grad-CAM heatmap\n",
        "last_conv_layer_name = \"conv5_block3_out\"  # Last convolutional layer in ResNet50\n",
        "heatmap = generate_gradcam(model, sample_image_array, last_conv_layer_name)\n",
        "\n",
        "# Overlay Grad-CAM on the image\n",
        "def overlay_heatmap(heatmap, original_image, alpha=0.4):\n",
        "    heatmap = np.uint8(255 * heatmap)  # Scale heatmap to 0-255\n",
        "    heatmap = plt.cm.jet(heatmap)[:, :, :3]  # Apply colormap\n",
        "    heatmap = tf.image.resize(heatmap, (224, 224)).numpy()  # Resize to match the image\n",
        "    overlayed_img = heatmap * alpha + original_image / 255.0  # Blend heatmap with the original image\n",
        "    overlayed_img = np.clip(overlayed_img, 0, 1)  # Ensure pixel values are within valid range\n",
        "    return overlayed_img\n",
        "\n",
        "overlayed_image = overlay_heatmap(heatmap, img_to_array(sample_image))\n",
        "\n",
        "# Plot Original Image and Grad-CAM\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(sample_image)\n",
        "plt.title(\"Original Image\", fontsize=18)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(overlayed_image)\n",
        "plt.title(\"Grad-CAM Visualization\", fontsize=18)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe1418a-c70d-47fe-9ecc-0c8e586213ac",
      "metadata": {
        "id": "fbe1418a-c70d-47fe-9ecc-0c8e586213ac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sample ground truth and predicted labels\n",
        "ground_truth = [\n",
        "    \"Breakfast\", \"Breakfast\", \"Soup\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Dessert\", \"Breakfast\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Main Course\", \"Side Dish\"\n",
        "]\n",
        "\n",
        "predicted = [\n",
        "    \"Breakfast\", \"Breakfast\", \"Soup\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Dessert\", \"Main Course\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Main Course\", \"Side Dish\"\n",
        "]\n",
        "\n",
        "# Calculate classification report\n",
        "report = classification_report(ground_truth, predicted, output_dict=True)\n",
        "\n",
        "# Convert the report to a DataFrame for visualization\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display the classification report\n",
        "import ace_tools as tools\n",
        "tools.display_dataframe_to_user(name=\"Classification Report for Food Categories\", dataframe=report_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e773a5d6-86ee-44a0-a4b2-e2538e128519",
      "metadata": {
        "id": "e773a5d6-86ee-44a0-a4b2-e2538e128519"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sample ground truth and predicted labels\n",
        "ground_truth = [\n",
        "    \"Breakfast\", \"Breakfast\", \"Soup\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Dessert\", \"Breakfast\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Main Course\", \"Side Dish\"\n",
        "]\n",
        "\n",
        "predicted = [\n",
        "    \"Breakfast\", \"Breakfast\", \"Soup\", \"Snack\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Dessert\", \"Main Course\", \"Breakfast\",\n",
        "    \"Main Course\", \"Breakfast\", \"Main Course\", \"Side Dish\"\n",
        "]\n",
        "\n",
        "# Calculate classification report\n",
        "report = classification_report(ground_truth, predicted, output_dict=True)\n",
        "\n",
        "# Convert the report to a DataFrame for visualization\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Print the classification report as a DataFrame\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b802f2-25b5-4e99-bd76-8b8c148b55b0",
      "metadata": {
        "id": "b7b802f2-25b5-4e99-bd76-8b8c148b55b0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Data from the table\n",
        "data = {\n",
        "    \"Class\": [\"Breakfast\", \"Dessert\", \"Main Course\", \"Side Dish\", \"Snack\", \"Soup\"],\n",
        "    \"Precision\": [1.0, 1.0, 0.75, 1.0, 1.0, 1.0],\n",
        "    \"Recall\": [0.857143, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
        "    \"F1-Score\": [0.923077, 1.0, 0.857143, 1.0, 1.0, 1.0],\n",
        "    \"Support\": [7.0, 1.0, 3.0, 1.0, 1.0, 1.0],\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Plot Precision, Recall, F1-Score for each class\n",
        "x = df[\"Class\"]\n",
        "bar_width = 0.2\n",
        "index = range(len(x))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar(index, df[\"Precision\"], width=bar_width, label=\"Precision\")\n",
        "plt.bar([i + bar_width for i in index], df[\"Recall\"], width=bar_width, label=\"Recall\")\n",
        "plt.bar([i + 2 * bar_width for i in index], df[\"F1-Score\"], width=bar_width, label=\"F1-Score\")\n",
        "\n",
        "plt.xticks([i + bar_width for i in index], x, rotation=45)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Evaluation Metrics by Class\", fontsize=18)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Support for each class\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, df[\"Support\"], color=\"skyblue\", label=\"Support\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Support\")\n",
        "plt.title(\"Support for Each Class\", fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae99d3d8-a8f7-4dc3-b5c4-f2afaee80142",
      "metadata": {
        "id": "ae99d3d8-a8f7-4dc3-b5c4-f2afaee80142"
      },
      "outputs": [],
      "source": [
        "# Create a radar chart for the metrics\n",
        "from math import pi\n",
        "\n",
        "# Data for radar chart\n",
        "classes = data[\"Class\"]\n",
        "metrics = [\"Precision\", \"Recall\", \"F1-Score\"]\n",
        "\n",
        "# Create the data structure for radar chart\n",
        "radar_data = pd.DataFrame(data).set_index(\"Class\")\n",
        "\n",
        "# Number of variables\n",
        "num_vars = len(metrics)\n",
        "\n",
        "# Create the angles for radar chart\n",
        "angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
        "angles += angles[:1]\n",
        "\n",
        "# Initialize the radar chart\n",
        "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "# Plot each class\n",
        "for class_name in classes:\n",
        "    values = radar_data.loc[class_name, metrics].tolist()\n",
        "    values += values[:1]  # Repeat the first value to close the circle\n",
        "    ax.plot(angles, values, label=class_name)\n",
        "    ax.fill(angles, values, alpha=0.1)\n",
        "\n",
        "# Add labels for each metric\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(metrics)\n",
        "\n",
        "# Set the y-labels\n",
        "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", size=10)\n",
        "\n",
        "# Add title and legend\n",
        "plt.title(\"Radar Chart of Evaluation Metrics by Class\", size=15, color=\"darkblue\", y=1.1)\n",
        "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1))\n",
        "\n",
        "# Show the radar chart\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d603731a-1473-41f8-b1ab-3729af0d17bf",
      "metadata": {
        "id": "d603731a-1473-41f8-b1ab-3729af0d17bf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from math import pi\n",
        "import pandas as pd\n",
        "\n",
        "# Data for the radar chart\n",
        "data = {\n",
        "    \"Class\": [\"Breakfast\", \"Dessert\", \"Main Course\", \"Side Dish\", \"Snack\", \"Soup\"],\n",
        "    \"Precision\": [1.0, 1.0, 0.75, 1.0, 1.0, 1.0],\n",
        "    \"Recall\": [0.857143, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
        "    \"F1-Score\": [0.923077, 1.0, 0.857143, 1.0, 1.0, 1.0],\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "categories = [\"Precision\", \"Recall\", \"F1-Score\"]\n",
        "num_vars = len(categories)\n",
        "\n",
        "# Set up the radar chart\n",
        "angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
        "angles += angles[:1]  # Close the circle\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "# Plot each class\n",
        "for i in range(len(df)):\n",
        "    values = df.loc[i, categories].values.flatten().tolist()\n",
        "    values += values[:1]  # Repeat the first value\n",
        "    ax.plot(angles, values, label=df.loc[i, \"Class\"])\n",
        "    ax.fill(angles, values, alpha=0.1)\n",
        "\n",
        "# Add labels\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories)\n",
        "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", size=8)\n",
        "\n",
        "# Add title and legend\n",
        "plt.title(\"Radar Chart of Evaluation Metrics by Class\", size=15, color=\"blue\", y=1.1)\n",
        "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 1.1))\n",
        "\n",
        "# Show the chart\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc7d7f5-c858-4f85-b57c-5c195e03464e",
      "metadata": {
        "id": "4bc7d7f5-c858-4f85-b57c-5c195e03464e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def automated_metrics_evaluation(actual_labels, predicted_labels, class_names):\n",
        "    \"\"\"\n",
        "    Automates the calculation and visualization of classification metrics.\n",
        "\n",
        "    Parameters:\n",
        "    - actual_labels: List of ground truth labels.\n",
        "    - predicted_labels: List of predicted labels.\n",
        "    - class_names: List of class names.\n",
        "\n",
        "    Returns:\n",
        "    - A DataFrame containing precision, recall, F1-score, and support for each class.\n",
        "    \"\"\"\n",
        "    # Generate the classification report\n",
        "    report = classification_report(actual_labels, predicted_labels, target_names=class_names, output_dict=True)\n",
        "\n",
        "    # Convert report to DataFrame\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_df = report_df.iloc[:-3, :]  # Exclude averages (optional)\n",
        "\n",
        "    # Display the classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report_df)\n",
        "\n",
        "    # Heatmap Visualization\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(report_df.iloc[:, :-1], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=True)\n",
        "    plt.title(\"Heatmap of Evaluation Metrics\")\n",
        "    plt.ylabel(\"Class\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return report_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23a5fb58-8eb1-4330-853a-fe4c03c14e38",
      "metadata": {
        "id": "23a5fb58-8eb1-4330-853a-fe4c03c14e38"
      },
      "outputs": [],
      "source": [
        "# Plotting training and validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for the graph\n",
        "epochs = list(range(1, 11))\n",
        "train_accuracy = [0.5, 0.6, 0.8, 0.9, 1.0, 1.0, 0.9, 0.8, 0.9, 0.9]\n",
        "validation_accuracy = [0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_accuracy, label=\"Training Accuracy\", marker='o')\n",
        "plt.plot(epochs, validation_accuracy, label=\"Validation Accuracy\", marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs. Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955859c9-da3b-4b0b-9705-a6697ebe46a1",
      "metadata": {
        "id": "955859c9-da3b-4b0b-9705-a6697ebe46a1"
      },
      "outputs": [],
      "source": [
        "# Data for the loss graph\n",
        "epochs = list(range(1, 11))\n",
        "train_loss = [5.0, 2.0, 1.5, 1.0, 0.8, 0.6, 0.5, 0.5, 0.6, 0.5]\n",
        "validation_loss = [6.0, 5.0, 3.0, 2.0, 4.0, 1.0, 5.0, 4.0, 5.0, 6.0]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss, label=\"Training Loss\", marker='o')\n",
        "plt.plot(epochs, validation_loss, label=\"Validation Loss\", marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs. Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fe1de3-be78-4b23-8232-422702c2b58b",
      "metadata": {
        "id": "b3fe1de3-be78-4b23-8232-422702c2b58b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the sample image for prediction\n",
        "sample_image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "sample_image = load_img(sample_image_path, target_size=(224, 224))  # Resize to model input size\n",
        "sample_image_array = img_to_array(sample_image) / 255.0  # Normalize pixel values\n",
        "\n",
        "# Titles for the models and mock evaluation metrics\n",
        "model_titles = [\"ResNet50\", \"VGG16\", \"InceptionV3\"]\n",
        "evaluation_metrics = [\n",
        "    {\"Loss\": 0.9390, \"Accuracy\": 0.5000},\n",
        "    {\"Loss\": 1.9283, \"Accuracy\": 0.0000},\n",
        "    {\"Loss\": 4.2100, \"Accuracy\": 0.0000},\n",
        "]\n",
        "\n",
        "# Visualization setup\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(sample_image)\n",
        "    ax.set_title(f\"{model_titles[i]}\\nLoss: {evaluation_metrics[i]['Loss']:.4f}, Accuracy: {evaluation_metrics[i]['Accuracy']:.4f}\", pad=10)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Visualization of Image Predictions by Different Models\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cfcc8a-b1b6-4456-aee7-6062cc00848f",
      "metadata": {
        "id": "92cfcc8a-b1b6-4456-aee7-6062cc00848f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the sample image for prediction\n",
        "sample_image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "sample_image = load_img(sample_image_path, target_size=(224, 224))  # Resize to model input size\n",
        "sample_image_array = img_to_array(sample_image) / 255.0  # Normalize pixel values\n",
        "\n",
        "# Titles for the models and mock evaluation metrics\n",
        "model_titles = [\"ResNet50\", \"VGG16\", \"InceptionV3\"]\n",
        "evaluation_metrics = [\n",
        "    {\"Loss\": 0.9390, \"Accuracy\": 0.5000},\n",
        "    {\"Loss\": 1.9283, \"Accuracy\": 0.0000},\n",
        "    {\"Loss\": 4.2100, \"Accuracy\": 0.0000},\n",
        "]\n",
        "\n",
        "# Visualization setup\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(sample_image)\n",
        "    ax.set_title(\n",
        "        f\"{model_titles[i]}\\nLoss: {evaluation_metrics[i]['Loss']:.4f}, Accuracy: {evaluation_metrics[i]['Accuracy']:.4f}\",\n",
        "        pad=20,  # Add more padding\n",
        "    )\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Add spacing between the rows and the main title\n",
        "plt.subplots_adjust(top=0.80, wspace=0.4)  # Adjust title and inter-image space\n",
        "\n",
        "# Main title\n",
        "plt.suptitle(\"Visualization of Image Predictions by Different Models\", fontsize=16, y=0.97)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887fb4f8-ca4d-4397-bd1e-0142c60389ec",
      "metadata": {
        "id": "887fb4f8-ca4d-4397-bd1e-0142c60389ec"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Define data augmentation transformations\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),  # Resize to a fixed size\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally with 50% probability\n",
        "    transforms.RandomRotation(degrees=15),  # Rotate randomly within Â±15 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
        "    transforms.RandomCrop(size=(150, 150)),  # Randomly crop a region of the image\n",
        "])\n",
        "\n",
        "# Example image path\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(image_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "img_pil = Image.fromarray(img_rgb)  # Convert to PIL format\n",
        "\n",
        "# Apply data augmentation\n",
        "augmented_images = [augmentation_transform(img_pil) for _ in range(5)]  # Generate 5 augmented versions\n",
        "\n",
        "# Display the original and augmented images\n",
        "fig, axes = plt.subplots(1, 6, figsize=(18, 6))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title(\"Original\", fontsize=16)  # Increased font size\n",
        "axes[0].axis('off')\n",
        "\n",
        "for i, aug_img in enumerate(augmented_images):\n",
        "    axes[i + 1].imshow(aug_img)\n",
        "    axes[i + 1].set_title(f\"Augmented {i + 1}\", fontsize=16)  # Increased font size\n",
        "    axes[i + 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedabe0d-7ba2-4244-96c0-7352fe7dbbcb",
      "metadata": {
        "id": "bedabe0d-7ba2-4244-96c0-7352fe7dbbcb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "import mahotas\n",
        "\n",
        "# Load the image\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert to grayscale\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Compute Canny edges\n",
        "canny_edges = cv2.Canny(image_gray, 100, 200)\n",
        "\n",
        "# Compute Local Binary Pattern (LBP)\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "lbp = local_binary_pattern(image_gray, n_points, radius, method=\"uniform\")\n",
        "\n",
        "# Compute Haralick features using mahotas\n",
        "haralick_features = mahotas.features.haralick(image_gray).mean(axis=0)\n",
        "contrast = haralick_features[1]  # Contrast\n",
        "homogeneity = haralick_features[2]  # Homogeneity\n",
        "energy = haralick_features[3]  # Energy\n",
        "correlation = haralick_features[4]  # Correlation\n",
        "\n",
        "# Extract Red and Green channels\n",
        "red_channel = image_rgb[:, :, 0]\n",
        "green_channel = image_rgb[:, :, 1]\n",
        "\n",
        "# Plot the results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0, 0].imshow(image_rgb)\n",
        "axes[0, 0].set_title(\"Original Image\")\n",
        "axes[0, 0].axis(\"off\")\n",
        "\n",
        "axes[0, 1].imshow(canny_edges, cmap=\"gray\")\n",
        "axes[0, 1].set_title(\"Canny Edges\")\n",
        "axes[0, 1].axis(\"off\")\n",
        "\n",
        "axes[0, 2].bar(['Contrast', 'Homogeneity', 'Energy', 'Correlation'],\n",
        "               [contrast, homogeneity, energy, correlation])\n",
        "axes[0, 2].set_title(\"Haralick Texture Features\")\n",
        "\n",
        "axes[1, 0].hist(lbp.ravel(), bins=np.arange(0, n_points + 3), density=True)\n",
        "axes[1, 0].set_title(\"LBP Features\")\n",
        "axes[1, 0].set_xlabel(\"Normalized Count\")\n",
        "\n",
        "axes[1, 1].imshow(red_channel, cmap=\"gray\")\n",
        "axes[1, 1].set_title(\"Red Channel\")\n",
        "axes[1, 1].axis(\"off\")\n",
        "\n",
        "axes[1, 2].imshow(green_channel, cmap=\"gray\")\n",
        "axes[1, 2].set_title(\"Green Channel\")\n",
        "axes[1, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5fd6e5d-46bf-4153-965a-2fefd6f372a4",
      "metadata": {
        "id": "b5fd6e5d-46bf-4153-965a-2fefd6f372a4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "import mahotas\n",
        "\n",
        "# Load the image\n",
        "image_path = r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert to grayscale\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Compute Canny edges\n",
        "canny_edges = cv2.Canny(image_gray, 100, 200)\n",
        "\n",
        "# Compute Local Binary Pattern (LBP)\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "lbp = local_binary_pattern(image_gray, n_points, radius, method=\"uniform\")\n",
        "\n",
        "# Compute Haralick features using mahotas\n",
        "haralick_features = mahotas.features.haralick(image_gray).mean(axis=0)\n",
        "contrast = haralick_features[1]  # Contrast\n",
        "homogeneity = haralick_features[2]  # Homogeneity\n",
        "energy = haralick_features[3]  # Energy\n",
        "correlation = haralick_features[4]  # Correlation\n",
        "\n",
        "# Extract Red and Green channels\n",
        "red_channel = image_rgb[:, :, 0]\n",
        "green_channel = image_rgb[:, :, 1]\n",
        "\n",
        "# Plot the results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes[0, 0].imshow(image_rgb)\n",
        "axes[0, 0].set_title(\"Original Image\", fontsize=18)  # Increased font size\n",
        "axes[0, 0].axis(\"off\")\n",
        "\n",
        "axes[0, 1].imshow(canny_edges, cmap=\"gray\")\n",
        "axes[0, 1].set_title(\"Canny Edges\", fontsize=18)  # Increased font size\n",
        "axes[0, 1].axis(\"off\")\n",
        "\n",
        "axes[0, 2].bar(['Contrast', 'Homogeneity', 'Energy', 'Correlation'],\n",
        "               [contrast, homogeneity, energy, correlation])\n",
        "axes[0, 2].set_title(\"Haralick Texture Features\", fontsize=18)  # Increased font size\n",
        "\n",
        "axes[1, 0].hist(lbp.ravel(), bins=np.arange(0, n_points + 3), density=True)\n",
        "axes[1, 0].set_title(\"LBP Features\", fontsize=16)  # Increased font size\n",
        "axes[1, 0].set_xlabel(\"Normalized Count\")\n",
        "\n",
        "axes[1, 1].imshow(red_channel, cmap=\"gray\")\n",
        "axes[1, 1].set_title(\"Red Channel\", fontsize=18)  # Increased font size\n",
        "axes[1, 1].axis(\"off\")\n",
        "\n",
        "axes[1, 2].imshow(green_channel, cmap=\"gray\")\n",
        "axes[1, 2].set_title(\"Green Channel\", fontsize=18)  # Increased font size\n",
        "axes[1, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d7e42e-9bf2-4990-8803-023fe976c0db",
      "metadata": {
        "id": "b3d7e42e-9bf2-4990-8803-023fe976c0db"
      },
      "outputs": [],
      "source": [
        "# Display the original and augmented images\n",
        "fig, axes = plt.subplots(1, 6, figsize=(20, 10))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title(\"Original\", fontsize=16)  # Increased font size\n",
        "axes[0].axis('off')\n",
        "\n",
        "for i, aug_img in enumerate(augmented_images):\n",
        "    axes[i + 1].imshow(aug_img)\n",
        "    axes[i + 1].set_title(f\"Augmented {i + 1}\", fontsize=18)  # Increased font size\n",
        "    axes[i + 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf66ed1-4e49-4227-9e74-4e25d77ba153",
      "metadata": {
        "id": "8cf66ed1-4e49-4227-9e74-4e25d77ba153"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1024558340-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\biryani\\\\5f814c0627.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1313104347-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-678434780-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\istockphoto-1254597620-612x612.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\south food\\\\images (1).jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\unni_appam\\\\5dbfa6d2d0.jpg\",\n",
        "    r\"C:\\\\Users\\\\Bala\\\\Desktop\\\\Indian Food Images\\\\navrattan_korma\\\\0a45c68b4d.jpg\"\n",
        "]\n",
        "\n",
        "# List of image labels (names)\n",
        "image_labels = [\n",
        "    \"Dosa\", \"Biryani\", \"Idly\", \"Pongal\", \"Chicken\", \"Fish\", \"Unniappam\", \"Kurma\"\n",
        "]\n",
        "\n",
        "# Set the common size for all images (e.g., 200x200 pixels)\n",
        "resize_dim = (200, 200)  # Width, Height\n",
        "\n",
        "# Normalization parameters (mean and std for each channel)\n",
        "mean = [0.485, 0.456, 0.406]  # Example mean (ImageNet standards)\n",
        "std = [0.229, 0.224, 0.225]  # Example std (ImageNet standards)\n",
        "\n",
        "# Create a 2x4 grid for the images\n",
        "rows, cols = 2, 4\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, 8))\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through the images and normalize them\n",
        "for i, (path, label) in enumerate(zip(image_paths, image_labels)):\n",
        "    # Read the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image from {path}\")\n",
        "        axes[i].axis('off')  # Hide axes for missing image\n",
        "        continue\n",
        "\n",
        "    # Resize the image to the specified dimensions\n",
        "    img_resized = cv2.resize(img, resize_dim)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Normalize the image\n",
        "    img_rgb = img_rgb / 255.0  # Scale to [0, 1]\n",
        "    img_normalized = (img_rgb - mean) / std  # Normalize using mean and std\n",
        "\n",
        "    # Convert back to [0, 1] range for visualization (denormalize)\n",
        "    img_display = (img_normalized * std) + mean\n",
        "    img_display = np.clip(img_display, 0, 1)  # Ensure values are within [0, 1]\n",
        "\n",
        "    # Display the normalized image in the corresponding subplot\n",
        "    axes[i].imshow(img_display)\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "    axes[i].set_title(label, fontsize=16)  # Use the label as the title with increased font size\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(len(image_paths), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "# Adjust spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a305bc0-938c-47f9-a092-fd3ed45fa933",
      "metadata": {
        "id": "0a305bc0-938c-47f9-a092-fd3ed45fa933"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}